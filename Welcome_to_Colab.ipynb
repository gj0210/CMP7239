{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gj0210/CMP7239/blob/main/Welcome_to_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "import joblib\n",
        "import streamlit as st\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.best_params = {}\n",
        "\n",
        "    def train_knn(self, X_train, y_train, param_grid=None, cv=5):\n",
        "        \"\"\"\n",
        "        Train K-Nearest Neighbors classifier with hyperparameter tuning.\n",
        "        \"\"\"\n",
        "        if param_grid is None:\n",
        "            param_grid = {\n",
        "                'n_neighbors': [3, 5, 7, 9, 11],\n",
        "                'weights': ['uniform', 'distance'],\n",
        "                'metric': ['euclidean', 'manhattan']\n",
        "            }\n",
        "\n",
        "        knn = KNeighborsClassifier()\n",
        "\n",
        "        # Grid search for best parameters\n",
        "        grid_search = GridSearchCV(\n",
        "            knn, param_grid, cv=cv, scoring='accuracy', n_jobs=-1\n",
        "        )\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Store best model and parameters\n",
        "        self.models['KNN'] = grid_search.best_estimator_\n",
        "        self.best_params['KNN'] = grid_search.best_params_\n",
        "\n",
        "        # Cross-validation scores\n",
        "        cv_scores = cross_val_score(\n",
        "            grid_search.best_estimator_, X_train, y_train, cv=cv\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'model': grid_search.best_estimator_,\n",
        "            'best_params': grid_search.best_params_,\n",
        "            'best_score': grid_search.best_score_,\n",
        "            'cv_scores': cv_scores,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std()\n",
        "        }\n",
        "\n",
        "    def train_decision_tree(self, X_train, y_train, param_grid=None, cv=5):\n",
        "        \"\"\"\n",
        "        Train Decision Tree classifier with hyperparameter tuning.\n",
        "        \"\"\"\n",
        "        if param_grid is None:\n",
        "            param_grid = {\n",
        "                'max_depth': [3, 5, 7, 10, None],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4],\n",
        "                'criterion': ['gini', 'entropy']\n",
        "            }\n",
        "\n",
        "        dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "        # Grid search for best parameters\n",
        "        grid_search = GridSearchCV(\n",
        "            dt, param_grid, cv=cv, scoring='accuracy', n_jobs=-1\n",
        "        )\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Store best model and parameters\n",
        "        self.models['Decision_Tree'] = grid_search.best_estimator_\n",
        "        self.best_params['Decision_Tree'] = grid_search.best_params_\n",
        "\n",
        "        # Cross-validation scores\n",
        "        cv_scores = cross_val_score(\n",
        "            grid_search.best_estimator_, X_train, y_train, cv=cv\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'model': grid_search.best_estimator_,\n",
        "            'best_params': grid_search.best_params_,\n",
        "            'best_score': grid_search.best_score_,\n",
        "            'cv_scores': cv_scores,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'feature_importance': dict(zip(X_train.columns, grid_search.best_estimator_.feature_importances_))\n",
        "        }\n",
        "\n",
        "    def train_random_forest(self, X_train, y_train, param_grid=None, cv=5):\n",
        "        \"\"\"\n",
        "        Train Random Forest classifier with hyperparameter tuning.\n",
        "        \"\"\"\n",
        "        if param_grid is None:\n",
        "            param_grid = {\n",
        "                'n_estimators': [50, 100, 200],\n",
        "                'max_depth': [3, 5, 7, 10, None],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4],\n",
        "                'max_features': ['sqrt', 'log2']\n",
        "            }\n",
        "\n",
        "        rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "        # Grid search for best parameters\n",
        "        grid_search = GridSearchCV(\n",
        "            rf, param_grid, cv=cv, scoring='accuracy', n_jobs=-1\n",
        "        )\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Store best model and parameters\n",
        "        self.models['Random_Forest'] = grid_search.best_estimator_\n",
        "        self.best_params['Random_Forest'] = grid_search.best_params_\n",
        "\n",
        "        # Cross-validation scores\n",
        "        cv_scores = cross_val_score(\n",
        "            grid_search.best_estimator_, X_train, y_train, cv=cv\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'model': grid_search.best_estimator_,\n",
        "            'best_params': grid_search.best_params_,\n",
        "            'best_score': grid_search.best_score_,\n",
        "            'cv_scores': cv_scores,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'feature_importance': dict(zip(X_train.columns, grid_search.best_estimator_.feature_importances_))\n",
        "        }\n",
        "\n",
        "    def train_all_models(self, X_train, y_train, cv=5):\n",
        "        \"\"\"\n",
        "        Train all models with optimized hyperparameters.\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "\n",
        "        st.info(\"Training K-Nearest Neighbors...\")\n",
        "        results['KNN'] = self.train_knn(X_train, y_train, cv=cv)\n",
        "\n",
        "        st.info(\"Training Decision Tree...\")\n",
        "        results['Decision_Tree'] = self.train_decision_tree(X_train, y_train, cv=cv)\n",
        "\n",
        "        st.info(\"Training Random Forest...\")\n",
        "        results['Random_Forest'] = self.train_random_forest(X_train, y_train, cv=cv)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def save_models(self, filepath_prefix='model'):\n",
        "        \"\"\"\n",
        "        Save trained models to disk.\n",
        "        \"\"\"\n",
        "        for name, model in self.models.items():\n",
        "            filename = f\"{filepath_prefix}_{name.lower()}.joblib\"\n",
        "            joblib.dump(model, filename)\n",
        "            st.success(f\"Model {name} saved as {filename}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"\n",
        "        Load a model from disk.\n",
        "        \"\"\"\n",
        "        return joblib.load(filepath)\n",
        "\n",
        "    def get_model_complexity(self):\n",
        "        \"\"\"\n",
        "        Get complexity information for each model.\n",
        "        \"\"\"\n",
        "        complexity = {}\n",
        "\n",
        "        if 'KNN' in self.models:\n",
        "            knn = self.models['KNN']\n",
        "            complexity['KNN'] = {\n",
        "                'n_neighbors': knn.n_neighbors,\n",
        "                'weights': knn.weights,\n",
        "                'metric': knn.metric,\n",
        "                'complexity_score': knn.n_neighbors  # Lower is more complex\n",
        "            }\n",
        "\n",
        "        if 'Decision_Tree' in self.models:\n",
        "            dt = self.models['Decision_Tree']\n",
        "            complexity['Decision_Tree'] = {\n",
        "                'max_depth': dt.max_depth,\n",
        "                'min_samples_split': dt.min_samples_split,\n",
        "                'min_samples_leaf': dt.min_samples_leaf,\n",
        "                'n_leaves': dt.get_n_leaves(),\n",
        "                'complexity_score': dt.get_n_leaves()  # More leaves = more complex\n",
        "            }\n",
        "\n",
        "        if 'Random_Forest' in self.models:\n",
        "            rf = self.models['Random_Forest']\n",
        "            complexity['Random_Forest'] = {\n",
        "                'n_estimators': rf.n_estimators,\n",
        "                'max_depth': rf.max_depth,\n",
        "                'min_samples_split': rf.min_samples_split,\n",
        "                'min_samples_leaf': rf.min_samples_leaf,\n",
        "                'complexity_score': rf.n_estimators * (rf.max_depth or 10)  # Approximation\n",
        "            }\n",
        "\n",
        "        return complexity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "TN_BGx-zOdPu",
        "outputId": "a2030f5b-5211-439d-dda3-091a094dc40b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3501200119.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89e095bc",
        "outputId": "1a0b9012-3a4c-49ab-de45-29c62eb74548"
      },
      "source": [
        "%pip install streamlit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.48.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.48.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.48.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d90a20"
      },
      "source": [
        "The error `ModuleNotFoundError: No module named 'streamlit'` occurs because the `streamlit` library, which is imported in the code, is not available in the current Python environment. To fix this, you need to install the library. The `!pip install streamlit` command in the previous cell will install the necessary library."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}